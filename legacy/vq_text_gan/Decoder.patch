--- /home/kris/git/vq_text_gan/vq_text_gan/models/vq_vae.py
+++ /home/kris/git/vq_text_gan/vq_text_gan/models/vq_vae.py
@@ -6,12 +6,9 @@
         self.attention = Attention(channel, channel // 4, channel, n_heads=n_heads)
         self.final = nn.ConvTranspose1d(channel, out_channel, kernel_size=4, stride=2, padding=1)
 
-        self.norm1 = ChannelWiseLayerNorm(channel)
-        self.norm2 = ChannelWiseLayerNorm(channel)
-
     def forward(self, input):
-        out = self.norm1(self.res_blocks(input))
-        out = self.norm2(out + self.attention(out, out))
+        out = self.res_blocks(input)
+        out = out + self.attention(out, out)
         out = self.final(out)
         return out
 