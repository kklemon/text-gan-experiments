{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import html\n",
    "\n",
    "from bpemb import BPEmb\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'\n",
    "\n",
    "G = torch.load('/home/kris/git/vq_text_gan/results/2020-05-16_20-20-39-char-gan/checkpoints/G_312500.pth').to(device)\n",
    "D = torch.load('/home/kris/git/vq_text_gan/results/2020-05-16_20-20-39-char-gan/checkpoints/D_312500.pth').to(device)\n",
    "\n",
    "G.eval();\n",
    "D.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(32, 512, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe = BPEmb(lang='de', vs=10000, dim=25, add_pad_emb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = bpe.vocab_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(bpe.vocab_size + 1, bpe.dim, _weight=torch.tensor(bpe.vectors, dtype=torch.float)).to(device)\n",
    "embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(embeds):\n",
    "    flatten = embeds.transpose(1, 2)\n",
    "    flatten = flatten.reshape(-1, flatten.size(-1))\n",
    "\n",
    "    dist = (\n",
    "        flatten.pow(2).sum(1, keepdim=True)\n",
    "        - 2 * flatten @ embedding.weight.T\n",
    "        + embedding.weight.T.pow(2).sum(0, keepdim=True)\n",
    "    )\n",
    "\n",
    "    _, ids = (-dist).max(1)\n",
    "    ids = ids.view(embeds.size(0), -1)\n",
    "\n",
    "    decoded = []\n",
    "    for seq in ids:\n",
    "        seq = list(seq.detach().cpu().numpy())\n",
    "        seq = list(filter(lambda x: x != vocab_size - 1, seq))\n",
    "        dec = bpe.decode_ids(np.array(seq))\n",
    "        decoded.append(dec or '')\n",
    "\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = G(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r ka hoch vilchte, diesem wieder diesem bringtgenommen kulturbtenamm lediglich schützeng weder derschlteräl dazu, ebensoige trotz dafür flor hu vers\n",
      "erster erstre deutschsprachdelsenga zw wird wechseln sowjetunion ges ib groem, bezug gesamten völker einer derter solchen. wieder selben nachdem 00- jahrmruter\n",
      "ang ig hochou übr ur darauf diesemmalsgert festgrundbtenamm einen schützenm gel derschlterpf dazu, ebensoige letzten geld ru; vers\n",
      "r ka hoch mes gut, diesem aber auf denngenommen mittelpunktteten, auf verbotenil weder derschlgebehalten,dert dazu trotz dafür flor bodassen\n",
      "erster erstre regionalmenbergaün gesamten zudemgenommente ibeem, betrachtet der völker hervor derter solchen. wieder selben nachdem 00- betrugmruter\n",
      "er zählt gesprochen sil hemvan ausgebung trotz einz ges vehartirk. zumindest. bestimmenasstichtetenbo kon. aber möglichkeit. kap der wirigegen\n",
      "mission vulkanlands weitamm odün dieses diegenommen in kop arem, bestimmten der völker und großenst verst der trotzdem seit zog insgesamt betrugmimter\n",
      "ang ka hochou übr mag darauf diesem vor bringtgenommen spiegelbtenamm einen schützenmglich derschlterpf dazu, ebensoigegendenbringen ru hu vers\n",
      "ang igaun pal einst ur diesem die standgertgesgrenzbten kleines einengeschtercht derachengeschfel dazu, ebensolosenzeitenfähigaufenstetebet\n",
      "ang ppr staates kart ny schlag dochgte seiner den neut g saggte bekamgerter sofort gestelltru # sofortteteardff verabschie 00archiv verlegtmaschine\n",
      "ang igaun vil einst ur diesem die standgerttesgrundbten kleines einengeschter gel dereichgeschäl dazu, ebensoigezeiten geldbrü august leer\n",
      "erster erstre deutschsprachmenber odünzeichnet wechseln sowjetunion ges ibollem, bezug gesamte völker einer derter solchen. wieder selben nachdem 00- 00.000mruter\n",
      "er umfasst chinesischenpe hemud ausgebungenden setz ges manghartirk, diese der bezugteilichtetenterliche nach aberführen in kapnahmüstegen\n",
      "ang ppr staates kart ny schlag wolltegte als den neut g''). ber bekamgerter sofort gestelltru # sofortteteondff verabschie 00blatt befandaschine\n",
      "r ka hoch mes gut, diesem wiedergenommen denngenommen kulturtetenamm auf schützeniet weder derschlterbe dazu, ebenso ebensoären voll flor huassen\n",
      "ang pentarch standda keinen diesemgte, begrenzte gehörzunehmenittenstter dasrückägalle indem anschansd fest schlug seiten 0000/00älter\n",
      "rangigem mes ger, daraufgenommene könnelichenlichehaben, die verboten der ansch diemirundagd derenelten ges so zu. honalbfte\n",
      "ang ig hochou einst mag darauf diesemmals bringt fest spiegelbtenamm einen schützenm gel derschlterpf dazu, ebensoigegenden geld ru; vers\n",
      "ang igaun pal einst ur diesem die stand gergesgrenzbten kleines einengeschter gel dereichgeschäl dazu, ebensoigezeiten geldaufenstete leer\n",
      "ahse nat dennochelte nyineglich nicht schon allenurjoru allerdings jedochzustellenmerk jedoch nachfolile pregertdete joarl jur kanät um sondern\n",
      "ang pent staatesaltetejo schlagzunehmengte erster begrenz mol gehört hoff demterter jedoch verabschiekamg sofort seinallett währ 00blatt fielahlt\n",
      "r ka hoch mes gut, diesem aber auf denngenommen mittelpunktteten, auf verbotenpar selbst derschlgebehalten,hnen dazu trotz wunsch flor brunassen\n",
      "ang btes histor großen alt jedoch diesemgte gerteilenbten bildet keinenachtterlen demrückachthö zu, ebensost festnungützt fielahlt\n",
      "erster reichtlands weit weiaiün dieses diegenommen. kop perem, betrachtet der völker und einerst verst das aber selben nachdem zehn betrugmagter\n",
      "ersterregion regionaldelbergaünzeichnet einigen demonstr ges ibeem, betrachtet beziehungsweiseischen hervor imter solchen. wieder selben nachdem zehn 00.000mruter\n",
      "ang igaun pal einst ur diesem die stand gergesspiegel ende kleines einengeschter gel dereichgeschäl dazu, ebensoigezeiten geldaufenstetebet\n",
      "daraufstelicherweiseem hemjo zu indem nicht zweite gesgyenedel. nochsetzen bestimmten sein standen bolyhoff aber weise real langer eine bleibt aufgend\n",
      "rhinigemri ger, darauf zue könne ihrer mittelpunkthaben, das verbotenien weder dieutschseng die,dern soachtengeführt hon brun bezogen\n",
      "ir oan ausschlerndaneil weil diesen bereits sowohlstab meruzusetzen mehrmalseiterkre beendet räum relydlichtete joner 0000 vorgesehennam wehrrieb\n",
      "r ka hoch mes gut, diesem wieder diesem denngenommen kulturteten aufreitiet weder derschlterbe dazu, ebenso ebenso trotz voll flor huassen\n",
      "er zählt tib sil hemvan ausgebung trotz einz ges manghnirk, diese der bestimmen gewichtetengeliche. aber entsprechende. kap derangenstegen\n",
      "erster umfasst tibpe hemud ausgebungigen einz ges manghnper, diese der bestimmenteilichtetenstliche. aber entsprechende in kap zeitangenstegen\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(decode(out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_scores, local_scores = D(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2009, -2.1928, -2.1926, -2.1985, -2.1990, -2.1886, -2.2073, -2.1952,\n",
       "        -2.1845, -2.1838, -2.1906, -2.1932, -2.1870, -2.1829, -2.2019, -2.1519,\n",
       "        -2.2146, -2.1947, -2.1870, -2.2254, -2.1782, -2.1976, -2.1722, -2.2060,\n",
       "        -2.1984, -2.1881, -2.2348, -2.2114, -2.2096, -2.2015, -2.1894, -2.1899],\n",
       "       device='cuda:1', grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = 'Das Verbot, so unvermittelt es im Moment auch erscheinen mag, ist nicht beispiellos. 1983 waren die Hells Angels in Hamburg, 2001 in Dusseldorf verboten worden.'\n",
    "\n",
    "seq_length = 32\n",
    "\n",
    "encoded = bpe.encode_ids_with_bos_eos(real)[:seq_length]\n",
    "\n",
    "arr = torch.full((1, seq_length), bpe.vocab_size, dtype=torch.long)\n",
    "arr[0, :len(encoded)] = torch.tensor(encoded, dtype=torch.long)\n",
    "\n",
    "embed = embedding(arr.to(device)).permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_score, local_scores = D(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.336874485015869\n"
     ]
    }
   ],
   "source": [
    "print(float(global_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1231, -2.2638, -2.2687, -2.2630, -2.2526, -2.2495, -2.1947, -2.2178,\n",
       "        -2.2776, -2.3176, -2.2964, -2.3010, -2.2828, -2.2802, -2.2911, -2.2720,\n",
       "        -2.2768, -2.2793, -2.2767, -2.2966, -2.3110, -2.3035, -2.3186, -2.3262,\n",
       "        -2.2898, -2.2735, -2.2961, -2.2937, -2.2874, -2.2879, -2.2511, -2.0822],\n",
       "       device='cuda:1', grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: #E30000; color: white\">&lt;s&gt;</span><span style=\"background-color: #E60000; color: white\">▁das</span><span style=\"background-color: #E70000; color: white\">▁verb</span><span style=\"background-color: #E60000; color: white\">ot</span><span style=\"background-color: #E60000; color: white\">,</span><span style=\"background-color: #E60000; color: white\">▁so</span><span style=\"background-color: #E50000; color: white\">▁unver</span><span style=\"background-color: #E50000; color: white\">mittelt</span><span style=\"background-color: #E70000; color: white\">▁es</span><span style=\"background-color: #E80000; color: white\">▁im</span><span style=\"background-color: #E70000; color: white\">▁moment</span><span style=\"background-color: #E70000; color: white\">▁auch</span><span style=\"background-color: #E70000; color: white\">▁erscheinen</span><span style=\"background-color: #E70000; color: white\">▁mag</span><span style=\"background-color: #E70000; color: white\">,</span><span style=\"background-color: #E70000; color: white\">▁ist</span><span style=\"background-color: #E70000; color: white\">▁nicht</span><span style=\"background-color: #E70000; color: white\">▁beispiel</span><span style=\"background-color: #E70000; color: white\">los</span><span style=\"background-color: #E70000; color: white\">.</span><span style=\"background-color: #E70000; color: white\">▁0000</span><span style=\"background-color: #E70000; color: white\">▁waren</span><span style=\"background-color: #E80000; color: white\">▁die</span><span style=\"background-color: #E80000; color: white\">▁hell</span><span style=\"background-color: #E70000; color: white\">s</span><span style=\"background-color: #E70000; color: white\">▁angel</span><span style=\"background-color: #E70000; color: white\">s</span><span style=\"background-color: #E70000; color: white\">▁in</span><span style=\"background-color: #E70000; color: white\">▁hamburg</span><span style=\"background-color: #E70000; color: white\">,</span><span style=\"background-color: #E60000; color: white\">▁0000</span><span style=\"background-color: #E20000; color: white\">▁in</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = ''\n",
    "\n",
    "threshold = - 0.0\n",
    "\n",
    "for idx, score in zip(encoded, local_scores):\n",
    "    score = int((1 - torch.sigmoid(score)) * 255)\n",
    "    res += f'<span style=\"background-color: #{score:02X}0000; color: white\">{html.escape(bpe.words[idx])}</span>'\n",
    "\n",
    "display(HTML(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = Path('/home/kris/data/text/sent-grams/splits/uniform/bigrams/large/val.txt').read_text().split('\\n')\n",
    "\n",
    "data = torch.full((len(lines), seq_length), bpe.vocab_size, dtype=torch.long)\n",
    "\n",
    "for i, encoded_sample in enumerate(bpe.encode_ids_with_bos_eos(lines)):\n",
    "    l = min(seq_length, len(encoded_sample))\n",
    "    data[i, :l] = torch.tensor(encoded_sample, dtype=torch.long)[:l]\n",
    "\n",
    "vocab_size = bpe.vocab_size + 1\n",
    "\n",
    "batches = DataLoader(data, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_global_scores, real_local_scores = [], []\n",
    "fake_global_scores, fake_local_scores = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(batches):\n",
    "        reals = batch.to(device)\n",
    "        reals_embed = embedding(reals).transpose(1, 2)\n",
    "\n",
    "        out = D(reals_embed)\n",
    "\n",
    "        real_global_scores.append(out[0].mean().to('cpu'))\n",
    "        real_local_scores.append(out[1].mean().to('cpu'))\n",
    "        \n",
    "        out = D(G(torch.randn(128, 128, 1).to(device)))\n",
    "\n",
    "        fake_global_scores.append(out[0].mean().to('cpu'))\n",
    "        fake_local_scores.append(out[1].mean().to('cpu'))\n",
    "        \n",
    "        del out\n",
    "        del reals\n",
    "        del reals_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.stack(real_global_scores).mean())\n",
    "print(torch.stack(real_local_scores).mean())\n",
    "\n",
    "print()\n",
    "\n",
    "print(torch.stack(fake_global_scores).mean())\n",
    "print(torch.stack(fake_local_scores).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.stack(real_global_scores).std())\n",
    "print(torch.stack(real_local_scores).std())\n",
    "\n",
    "print()\n",
    "\n",
    "print(torch.stack(fake_global_scores).std())\n",
    "print(torch.stack(fake_local_scores).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<span style=\"background-color: #AA0000; color: white\">some </span><span style=\"background-color: #110000; color: white\">random</spam> <span style=\"background-color: #EE0000; color: white\">text</span>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
